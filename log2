0.18.1
[nltk_data] Downloading package averaged_perceptron_tagger to
[nltk_data]     /home/brij/nltk_data...
[nltk_data]   Package averaged_perceptron_tagger is already up-to-
[nltk_data]       date!
[nltk_data] Downloading package punkt to /home/brij/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
Reading complete dataset.
Splitting into train (80%) and test (20%).
Class ==> unknown, #samples ==> 272
Class ==> what, #samples ==> 609
Class ==> who, #samples ==> 402
Class ==> when, #samples ==> 96
Class ==> affirmation, #samples ==> 104

Extracting word features (a length(sentence) size dictionary containing True if word is present in sentence).
('how did serfdom develop in and then leave russia ?', 'unknown')
[('how', 'wrb', 'unknown'), ('did', 'vbd', 'unknown'), ('serfdom', 'vb', 'unknown'), ('develop', 'vb', 'unknown'), ('in', 'in', 'unknown'), ('and', 'cc', 'unknown'), ('then', 'rb', 'unknown'), ('leave', 'vb', 'unknown'), ('russia', 'nn', 'unknown'), ('?', '.', 'unknown')]
[['bias', 'word.lower=how', 'word[-3:]=how', 'word[-2:]=ow', 'word.isupper=False', 'word.istitle=False', 'word.isdigit=False', 'postag=wrb', 'postag[:2]=wr', 'BOS', '+1:word.lower=did', '+1:word.istitle=False', '+1:word.isupper=False', '+1:postag=vbd', '+1:postag[:2]=vb'], ['bias', 'word.lower=did', 'word[-3:]=did', 'word[-2:]=id', 'word.isupper=False', 'word.istitle=False', 'word.isdigit=False', 'postag=vbd', 'postag[:2]=vb', '-1:word.lower=how', '-1:word.istitle=False', '-1:word.isupper=False', '-1:postag=wrb', '-1:postag[:2]=wr', '+1:word.lower=serfdom', '+1:word.istitle=False', '+1:word.isupper=False', '+1:postag=vb', '+1:postag[:2]=vb'], ['bias', 'word.lower=serfdom', 'word[-3:]=dom', 'word[-2:]=om', 'word.isupper=False', 'word.istitle=False', 'word.isdigit=False', 'postag=vb', 'postag[:2]=vb', '-1:word.lower=did', '-1:word.istitle=False', '-1:word.isupper=False', '-1:postag=vbd', '-1:postag[:2]=vb', '+1:word.lower=develop', '+1:word.istitle=False', '+1:word.isupper=False', '+1:postag=vb', '+1:postag[:2]=vb'], ['bias', 'word.lower=develop', 'word[-3:]=lop', 'word[-2:]=op', 'word.isupper=False', 'word.istitle=False', 'word.isdigit=False', 'postag=vb', 'postag[:2]=vb', '-1:word.lower=serfdom', '-1:word.istitle=False', '-1:word.isupper=False', '-1:postag=vb', '-1:postag[:2]=vb', '+1:word.lower=in', '+1:word.istitle=False', '+1:word.isupper=False', '+1:postag=in', '+1:postag[:2]=in'], ['bias', 'word.lower=in', 'word[-3:]=in', 'word[-2:]=in', 'word.isupper=False', 'word.istitle=False', 'word.isdigit=False', 'postag=in', 'postag[:2]=in', '-1:word.lower=develop', '-1:word.istitle=False', '-1:word.isupper=False', '-1:postag=vb', '-1:postag[:2]=vb', '+1:word.lower=and', '+1:word.istitle=False', '+1:word.isupper=False', '+1:postag=cc', '+1:postag[:2]=cc'], ['bias', 'word.lower=and', 'word[-3:]=and', 'word[-2:]=nd', 'word.isupper=False', 'word.istitle=False', 'word.isdigit=False', 'postag=cc', 'postag[:2]=cc', '-1:word.lower=in', '-1:word.istitle=False', '-1:word.isupper=False', '-1:postag=in', '-1:postag[:2]=in', '+1:word.lower=then', '+1:word.istitle=False', '+1:word.isupper=False', '+1:postag=rb', '+1:postag[:2]=rb'], ['bias', 'word.lower=then', 'word[-3:]=hen', 'word[-2:]=en', 'word.isupper=False', 'word.istitle=False', 'word.isdigit=False', 'postag=rb', 'postag[:2]=rb', '-1:word.lower=and', '-1:word.istitle=False', '-1:word.isupper=False', '-1:postag=cc', '-1:postag[:2]=cc', '+1:word.lower=leave', '+1:word.istitle=False', '+1:word.isupper=False', '+1:postag=vb', '+1:postag[:2]=vb'], ['bias', 'word.lower=leave', 'word[-3:]=ave', 'word[-2:]=ve', 'word.isupper=False', 'word.istitle=False', 'word.isdigit=False', 'postag=vb', 'postag[:2]=vb', '-1:word.lower=then', '-1:word.istitle=False', '-1:word.isupper=False', '-1:postag=rb', '-1:postag[:2]=rb', '+1:word.lower=russia', '+1:word.istitle=False', '+1:word.isupper=False', '+1:postag=nn', '+1:postag[:2]=nn'], ['bias', 'word.lower=russia', 'word[-3:]=sia', 'word[-2:]=ia', 'word.isupper=False', 'word.istitle=False', 'word.isdigit=False', 'postag=nn', 'postag[:2]=nn', '-1:word.lower=leave', '-1:word.istitle=False', '-1:word.isupper=False', '-1:postag=vb', '-1:postag[:2]=vb', '+1:word.lower=?', '+1:word.istitle=False', '+1:word.isupper=False', '+1:postag=.', '+1:postag[:2]=.'], ['bias', 'word.lower=?', 'word[-3:]=?', 'word[-2:]=?', 'word.isupper=False', 'word.istitle=False', 'word.isdigit=False', 'postag=.', 'postag[:2]=.', '-1:word.lower=russia', '-1:word.istitle=False', '-1:word.isupper=False', '-1:postag=nn', '-1:postag[:2]=nn', 'EOS']]
============training for fold 0 ...============

Training Naive Bayes Classifier.
Testing Naive Bayes.
Accuracy: 0.916387959866
Training Maxent Classifier.
Testing Maxent Classifier.
Accuracy: 0.822742474916
['feature.minfreq', 'feature.possible_states', 'feature.possible_transitions', 'c1', 'c2', 'max_iterations', 'num_memories', 'epsilon', 'period', 'delta', 'linesearch', 'max_linesearch']
[('what', 'wp', 'what'), ('1920s', 'cd', 'what'), ('cowboy', 'nn', 'what'), ('star', 'nn', 'what'), ('rode', 'nn', 'what'), ('tony', 'in', 'what'), ('the', 'dt', 'what'), ('wonder', 'nn', 'what'), ('horse', 'nn', 'what'), ('?', '.', 'what')]
what 1920s cowboy star rode tony the wonder horse ?


('Predicted:', 'what what what what what what what what what what')
('Correct:  ', 'what what what what what what what what what what')
set(['unknown', 'what', 'affirmation', 'when', 'who'])
             precision    recall  f1-score   support

affirmation       1.00      0.72      0.84       199
    unknown       0.83      0.96      0.89       581
       what       0.96      0.97      0.97      1148
       when       0.89      0.83      0.86       164
        who       1.00      0.96      0.98       809

avg / total       0.94      0.94      0.94      2901

============training for fold 1 ...============

Training Naive Bayes Classifier.
Testing Naive Bayes.
Accuracy: 0.892617449664
Training Maxent Classifier.
Testing Maxent Classifier.
Accuracy: 0.852348993289
['feature.minfreq', 'feature.possible_states', 'feature.possible_transitions', 'c1', 'c2', 'max_iterations', 'num_memories', 'epsilon', 'period', 'delta', 'linesearch', 'max_linesearch']
[('could', 'md', 'affirmation'), ('this', 'dt', 'affirmation'), ('be', 'vb', 'affirmation'), ('used', 'vbn', 'affirmation'), ('outside', 'in', 'affirmation'), ('in', 'in', 'affirmation'), ('a', 'dt', 'affirmation'), ('enclosed', 'jj', 'affirmation'), ('patio', 'nn', 'affirmation'), ('and', 'cc', 'affirmation'), ('work', 'nn', 'affirmation'), ('accurately', 'rb', 'affirmation'), ('throughout', 'in', 'affirmation'), ('the', 'dt', 'affirmation'), ('seasons', 'nns', 'affirmation'), ('?', '.', 'affirmation')]
could this be used outside in a enclosed patio and work accurately throughout the seasons ?


('Predicted:', 'affirmation affirmation affirmation affirmation affirmation affirmation affirmation affirmation affirmation affirmation affirmation affirmation affirmation affirmation affirmation affirmation')
('Correct:  ', 'affirmation affirmation affirmation affirmation affirmation affirmation affirmation affirmation affirmation affirmation affirmation affirmation affirmation affirmation affirmation affirmation')
set(['unknown', 'what', 'affirmation', 'when', 'who'])
             precision    recall  f1-score   support

affirmation       0.97      0.82      0.89       222
    unknown       0.92      0.89      0.91       550
       what       0.93      1.00      0.96      1203
       when       0.79      0.53      0.63       154
        who       0.98      1.00      0.99       777

avg / total       0.94      0.94      0.94      2906

============training for fold 2 ...============

Training Naive Bayes Classifier.
Testing Naive Bayes.
Accuracy: 0.925675675676
Training Maxent Classifier.
Testing Maxent Classifier.
Accuracy: 0.834459459459
['feature.minfreq', 'feature.possible_states', 'feature.possible_transitions', 'c1', 'c2', 'max_iterations', 'num_memories', 'epsilon', 'period', 'delta', 'linesearch', 'max_linesearch']
[('what', 'wp', 'what'), ('is', 'vbz', 'what'), ('a', 'dt', 'what'), ('wop', 'nn', 'what'), ('?', '.', 'what')]
what is a wop ?


('Predicted:', 'what what what what what')
('Correct:  ', 'what what what what what')
set(['unknown', 'what', 'affirmation', 'when', 'who'])
             precision    recall  f1-score   support

affirmation       1.00      1.00      1.00       175
    unknown       0.98      0.93      0.96       569
       what       0.97      0.98      0.97      1237
       when       0.95      0.83      0.89       181
        who       0.96      1.00      0.98       754

avg / total       0.97      0.97      0.97      2916

============training for fold 3 ...============

Training Naive Bayes Classifier.
Testing Naive Bayes.
Accuracy: 0.898648648649
Training Maxent Classifier.
Testing Maxent Classifier.
Accuracy: 0.804054054054
['feature.minfreq', 'feature.possible_states', 'feature.possible_transitions', 'c1', 'c2', 'max_iterations', 'num_memories', 'epsilon', 'period', 'delta', 'linesearch', 'max_linesearch']
[('what', 'wdt', 'what'), ('does', 'vbz', 'what'), ('the', 'dt', 'what'), ('latin', 'jj', 'what'), ('ante', 'jj', 'what'), ('mortem', 'nn', 'what'), ('mean', 'nn', 'what'), ('?', '.', 'what')]
what does the latin ante mortem mean ?


('Predicted:', 'what what what what what what what what')
('Correct:  ', 'what what what what what what what what')
set(['unknown', 'what', 'affirmation', 'when', 'who'])
             precision    recall  f1-score   support

affirmation       1.00      0.88      0.93       196
    unknown       0.91      0.83      0.87       602
       what       0.91      0.98      0.94      1212
       when       0.92      0.91      0.91       158
        who       0.99      0.97      0.98       862

avg / total       0.94      0.94      0.94      3030

============training for fold 4 ...============

Training Naive Bayes Classifier.
Testing Naive Bayes.
Accuracy: 0.87074829932
Training Maxent Classifier.
Testing Maxent Classifier.
Accuracy: 0.812925170068
['feature.minfreq', 'feature.possible_states', 'feature.possible_transitions', 'c1', 'c2', 'max_iterations', 'num_memories', 'epsilon', 'period', 'delta', 'linesearch', 'max_linesearch']
[('who', 'wp', 'who'), ('is', 'vbz', 'who'), ('robin', 'jj', 'who'), ('williams', 'nns', 'who'), ('?', '.', 'who')]
who is robin williams ?


('Predicted:', 'who who who who who')
('Correct:  ', 'who who who who who')
set(['unknown', 'what', 'affirmation', 'when', 'who'])
             precision    recall  f1-score   support

affirmation       1.00      0.87      0.93       157
    unknown       0.89      0.92      0.90       566
       what       0.95      0.99      0.97      1242
       when       0.81      0.87      0.84       165
        who       1.00      0.91      0.95       773

avg / total       0.94      0.94      0.94      2903

